{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03d4950d",
   "metadata": {},
   "source": [
    "# Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9118f6",
   "metadata": {},
   "source": [
    "## North"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6741fd87",
   "metadata": {},
   "source": [
    "- change from \"สรรพ.\" to \"ส.\"\n",
    "- change from \"สำ.\" to \"สำนวน.\"\n",
    "- change from \"ลัก.\" to \"น.\"\n",
    "- if คำอุทานมี POS ไม่แก้ else เปลี่ยน r\"อุทาน\\.|คำอุทาน\\.\" เป็น \"อ.\"  \n",
    "- ลบ note หรือ comment กำกับข้อมูลใน column 4-5\n",
    "- ค้างทุง \"ความเปรียบ\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c35986",
   "metadata": {},
   "source": [
    "## South"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3819f13",
   "metadata": {},
   "source": [
    "- change from \"สรรพ.\" to \"ส.\"\n",
    "- change from \"ลัก.\" to \"น.\"\n",
    "- change from \"อุ\" to \"อ.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aefa8bb",
   "metadata": {},
   "source": [
    "## Isan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dda5bb",
   "metadata": {},
   "source": [
    "- change from \"สรรพ.\" to \"ส.\"\n",
    "- change from \"สำ.\" to \"สำนวน.\"\n",
    "- change from \"ลัก.\" to \"น.\"\n",
    "- change from \"อุ\" to \"อ.\"\n",
    "- remove any note or comment in 5th column\n",
    "- clear the first row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c47ae38",
   "metadata": {},
   "source": [
    "## Central"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef87309",
   "metadata": {},
   "source": [
    "# Main Program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9b57fe",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad69cf55-a308-4e93-a52a-4610b92686f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading packages\n",
    "\n",
    "# !pip3 install numpy\n",
    "# !pip3 install pandas\n",
    "# !pip3 install csv\n",
    "# !pip3 install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b8b3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "# north_path = r\"datasets\\พจนานุกรมภาษาถิ่นเหนือ.xlsx\"\n",
    "# isan_path = r\"datasets\\พจนานุกรมภาษาถิ่นอีสาน.xlsx\"\n",
    "# south_path = r\"datasets\\พจนานุกรมภาษาถิ่นใต้.xlsx\"\n",
    "# orst_path = r\"datasets\\ราชบัณฑิตฯ\"\n",
    "\n",
    "# second datasets\n",
    "north_path = r\"datasets_copy\\พจนานุกรมภาษาถิ่นเหนือ.xlsx\"\n",
    "isan_path = r\"datasets_copy\\พจนานุกรมภาษาถิ่นอีสาน.xlsx\"\n",
    "south_path = r\"datasets_copy\\พจนานุกรมภาษาถิ่นใต้.xlsx\"\n",
    "orst_path = r\"datasets_copy\\ราชบัณฑิตฯ\"\n",
    "\n",
    "def load_sheets(file_path, exclude_sheets):\n",
    "    all_sheets = pd.ExcelFile(file_path).sheet_names\n",
    "    importing_sheets = [sheet for sheet in all_sheets if sheet not in exclude_sheets]\n",
    "    return pd.read_excel(file_path, sheet_name=importing_sheets, header=None)\n",
    "\n",
    "# north_df = load_sheets(north_path, ['อักษรย่อชนิดคำ', 'Example', 'note'])\n",
    "\n",
    "north_df = pd.read_excel(north_path, sheet_name=None, header=None)\n",
    "isan_df = pd.read_excel(isan_path, sheet_name=None, header=None)\n",
    "south_df = pd.read_excel(south_path, sheet_name=None, header=None)\n",
    "\n",
    "def load_excel(directory):\n",
    "    excel_files = {}\n",
    "    for filename in os.listdir(directory):\n",
    "        name = os.path.splitext(filename)[0]\n",
    "        excel_files[name] = pd.read_excel(os.path.join(directory, filename), header=None)\n",
    "    return excel_files\n",
    "\n",
    "orst_df = load_excel(orst_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38649c71",
   "metadata": {},
   "source": [
    "## Inspect the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db0730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to copy\n",
    "\n",
    "north = north_df.copy()\n",
    "isan = isan_df.copy()\n",
    "south = south_df.copy()\n",
    "orst = orst_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7b0ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the data\n",
    "\n",
    "def inspect(num=10, *dfs):\n",
    "  for df in dfs:\n",
    "    for key in df.keys():\n",
    "      print(f\"{key}\\n{df[key].head(num)}\\n\")\n",
    "\n",
    "inspect(10, orst)\n",
    "# inspect(10, north, south, isan, orst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee626f67",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8e3e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning\n",
    "\n",
    "def cleaning(*dfs):\n",
    "    for df in dfs:\n",
    "        removed = [\n",
    "            'ช่อง 1', 'ลูกคำ/ ความหมาย', 'แม่คำ', 'ความหมายลูกคำ คำสื่อ',\n",
    "            'headword', '2', '3']\n",
    "\n",
    "        for key in df.keys():\n",
    "            df[key] = df[key][~df[key].apply(lambda row: any(string in str(val) for string in removed for val in row), axis=1)]\n",
    "            \n",
    "            if df == north:\n",
    "                df[key] = df[key].dropna(how='all')\n",
    "                df[key] = df[key].drop(df[key].columns[2:], axis=1)\n",
    "\n",
    "            elif df == orst:\n",
    "                # remove last column\n",
    "                df[key] = df[key].iloc[:, :-1]\n",
    "\n",
    "                # if the first cell is null, replace with second cell\n",
    "                df[key].iloc[:, 0] = df[key].apply(lambda row: row.iloc[1] if pd.isnull(row.iloc[0]) else row.iloc[0], axis=1)\n",
    "                \n",
    "                # drop the second column\n",
    "                df[key] = df[key].drop(columns=[df[key].columns[1]])\n",
    "\n",
    "                # reset the index\n",
    "                df[key] = df[key].reset_index(drop=True)\n",
    "                df[key].columns = ['word', 'meaning']\n",
    "\n",
    "cleaning(orst)\n",
    "# cleaning(north, isan, south, orst)\n",
    "\n",
    "# inspect(20, orst)\n",
    "# inspect(10, north, south, isan, orst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3429141c",
   "metadata": {},
   "source": [
    "## Split POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6324399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# orst\n",
    "\n",
    "def rearrange(df = orst):\n",
    "  for key in orst.keys():\n",
    "    orst[key][\"คำ\"] = orst[key]['word']\n",
    "    orst[key]['meaning'] = orst[key]['meaning'].str.split(';')\n",
    "    orst[key] = orst[key].explode('meaning')\n",
    "    orst[key] = orst[key].drop_duplicates()\n",
    "    orst[key] = orst[key].reset_index(drop=True)\n",
    "\n",
    "    # split by POS\n",
    "\n",
    "    orst[key][[\"POS\", \"ความหมาย\"]] = orst[key]['meaning'].str.extract(\n",
    "      r\"^(น\\.|ก\\.|ว\\.|สัน\\.|สำนวน\\.|ล\\.|ส\\.|อ\\.)(.*)$\", expand=True)\n",
    "    orst[key][\"POS\"].fillna(\"\", inplace=True)\n",
    "    orst[key][\"ความหมาย\"] = orst[key].apply(lambda row: row[2] if row[\"POS\"] == \"\" else row[\"ความหมาย\"], axis=1)\n",
    "      \n",
    "    # remove first two columns\n",
    "    \n",
    "    orst[key] = orst[key].iloc[:, 2:]\n",
    "\n",
    "rearrange()\n",
    "\n",
    "# def clean_whitespace(text):\n",
    "#     if isinstance(text, str): \n",
    "#         return ' '.join(text.split())\n",
    "#     return text\n",
    "\n",
    "# for key in orst.keys():\n",
    "#   for column in orst[key].columns:\n",
    "#     if orst[key][column].dtype == 'object':\n",
    "#       orst[key][column] = orst[key][column].apply(clean_whitespace)\n",
    "\n",
    "def clean_whitespace(df):\n",
    "  for key in df.keys():\n",
    "    for column in df[key].columns:\n",
    "      if df[key][column].dtype == 'object':\n",
    "        df[key][column] = df[key][column].apply(\n",
    "          lambda text: ' '.join(text.split()) if isinstance(text, str) else text\n",
    "        )\n",
    "  return df\n",
    "\n",
    "orst = clean_whitespace(orst)\n",
    "\n",
    "# inspect(10, orst)\n",
    "\n",
    "orst['หมวด_ก(3881)'].head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974c5419",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bd83e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original\n",
    "\n",
    "pattern = r\"(น\\.|ก\\.|ว\\.|สัน\\.|สำนวน\\.|ล\\.|ส\\.|อ\\.)\"\n",
    "\"\"\"\n",
    "น. --> นาม\n",
    "ก. --> กริยา\n",
    "ว. --> วิเศษณ์\n",
    "สัน. --> สันธาน\n",
    "สำนวน. --> สำนวน\n",
    "ล. --> ลักษณนาม\n",
    "ส. --> สรรพนาม\n",
    "อ. --> อุทาน\n",
    "\"\"\"\n",
    "\n",
    "def split_pos_and_definition(df):\n",
    "    def split_row(row):\n",
    "        matches = []\n",
    "        seen = set()\n",
    "        alt_forms = [\"ก็ว่า.\", \"ก็เรียก.\"]\n",
    "        \n",
    "        text = ' '.join(str(val) for val in row if pd.notna(val))\n",
    "        \n",
    "        # temporary value 1\n",
    "        temp_text = text\n",
    "\n",
    "        # split_text = re.split(r\";\", temp_text)\n",
    "        # print(split_text)\n",
    "\n",
    "        # replace POS\n",
    "        # temp_text = re.sub(r'ลัก\\.', r'ล.', temp_text)\n",
    "        # temp_text = re.sub(r'สรรพ\\.', r'ส.', temp_text)\n",
    "        # temp_text = re.sub(r'คำอุทาน\\.|อุทาน\\.', r'อ.', temp_text)\n",
    "\n",
    "        # remove alternative forms\n",
    "        # temp_text = re.sub(r'\\sดู\\s.+', '', temp_text)\n",
    "        # temp_text = re.sub(r'\\(ดู\\s*-\\s*.+\\)$', '', temp_text)\n",
    "        # temp_text = re.sub(r'\\(ดูเพิ่มเติมที่ .*\\)', '', temp_text)\n",
    "        # temp_text = re.sub(r'\"([^\"]*)\"', r'\\1', temp_text)\n",
    "\n",
    "        # temporary value 2\n",
    "        text = temp_text\n",
    "\n",
    "        matches = [match for match in re.findall(pattern, text) if not (match in seen or seen.add(match))]\n",
    "        new_text = text\n",
    "        if len(matches) > 1:\n",
    "            first_string = matches[1][:-1]\n",
    "            second_string = matches[0][:-1]\n",
    "            \n",
    "            # >1 POS & 1 meaning\n",
    "            if re.search(rf'{first_string}\\.\\s?{second_string}\\.|{second_string}\\.\\s?{first_string}\\.', text):\n",
    "                text = re.sub(rf'{first_string}\\.', '', text, count=1)\n",
    "                new_text = re.sub(rf'{second_string}\\.', '', new_text, count=1)\n",
    "            \n",
    "            # >1 POS & >1 meaning\n",
    "            else:\n",
    "                text = re.sub(rf'{first_string}\\..*$', '', text, count=1)\n",
    "        \n",
    "        elif len(matches) < 1:\n",
    "            # check \"ก็ว่า.\" and \"ก็เรียก.\"\n",
    "            if any(alt_forms) in text:\n",
    "                print(text)\n",
    "            else:\n",
    "                text = ''\n",
    "\n",
    "        # typos\n",
    "        text = text.replace(\"“\", \"\\\"\").replace(\"”\", \"\\\"\").replace(\"''\", \"\\\"\").replace(\"‘\", \"'\").replace(\"’\", \"'\")\n",
    "\n",
    "        parts = re.split(pattern, text)\n",
    "        word = parts[0].strip()\n",
    "        pos = parts[1].strip() if len(parts) > 1 else ''\n",
    "        definition = ' '.join(parts[2:]).strip() if len(parts) > 2 else ''\n",
    "        definition = definition.strip()\n",
    "        return pd.Series([word, pos, definition])\n",
    "\n",
    "    for key in df.keys():\n",
    "        df[key].columns = ['คำ', 'POS', 'ความหมาย']\n",
    "    return df\n",
    "\n",
    "# north = split_pos_and_definition(north)\n",
    "# isan = split_pos_and_definition(isan)\n",
    "# south = split_pos_and_definition(south)\n",
    "orst = split_pos_and_definition(orst)\n",
    "\n",
    "inspect(20, orst)\n",
    "# inspect(10, north, isan, south, orst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384930b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_blank_words(iter=2, *dfs):\n",
    "    for df in dfs:\n",
    "        for _ in range(iter):\n",
    "            for key in df.keys():\n",
    "                df[key].dropna(how='all', inplace=True)\n",
    "                df[key].replace(\"\", np.nan, inplace=True)\n",
    "                df[key] = df[key].infer_objects(copy=False)\n",
    "                df[key].ffill(axis=0, inplace=True)\n",
    "        return df\n",
    "\n",
    "fill_blank_words(2, orst)\n",
    "# fill_blank_words(2, north, isan, south, orst)\n",
    "\n",
    "inspect(10, orst)\n",
    "# inspect(10, north, isan, south, orst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7207b13c",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2dbaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output\n",
    "\n",
    "def df_to_csv(dfs, region, path):\n",
    "    for sheet, df in dfs.items():\n",
    "        file = f\"{path}/{region}_{sheet}.csv\"\n",
    "        df.to_csv(file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "regions = {\n",
    "    # 'north': north,\n",
    "    # 'isan': isan,\n",
    "    # 'south': south,\n",
    "    'cen': orst\n",
    "    }\n",
    "\n",
    "for region, dfs in regions.items():\n",
    "    df_to_csv(dfs, region, r\"output\\csv_test2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90951ffb",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ff3643",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "th_dialect_dict",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
