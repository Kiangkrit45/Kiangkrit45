{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03d4950d",
   "metadata": {},
   "source": [
    "# Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9118f6",
   "metadata": {},
   "source": [
    "## North"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6741fd87",
   "metadata": {},
   "source": [
    "- ลบ note หรือ comment กำกับข้อมูลใน column 4-5\n",
    "- ใช้ regex ลบ ดู, ก็ว่า, ก็เรียก"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c35986",
   "metadata": {},
   "source": [
    "## South"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3819f13",
   "metadata": {},
   "source": [
    "- มีการใช้เลขไทย [๑., ๑).] เพื่อแสดง POS ที่หลากหลาย\n",
    "- \"อาลปนะ.\"\n",
    "- \"แสลง.\" instead of \"POS\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9aefa8bb",
   "metadata": {},
   "source": [
    "## Isan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dda5bb",
   "metadata": {},
   "source": [
    "- change from \"สรรพ.\" to \"ส.\"\n",
    "- change from \"สำ.\" to \"สำนวน.\"\n",
    "- change from \"ลัก.\" to \"น.\"\n",
    "- change from \"อุ\" to \"อ.\"\n",
    "- remove any note or comment in 5th column\n",
    "- clear the first row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c47ae38",
   "metadata": {},
   "source": [
    "## Central"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef87309",
   "metadata": {},
   "source": [
    "# Main Program"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9b57fe",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad69cf55-a308-4e93-a52a-4610b92686f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading packages\n",
    "\n",
    "# !pip3 install numpy\n",
    "# !pip3 install pandas\n",
    "# !pip3 install csv\n",
    "# !pip3 install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b8b3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "north_path = r\"datasets\\พจนานุกรมภาษาถิ่นเหนือ - Copy.xlsx\"\n",
    "isan_path = r\"datasets\\พจนานุกรมภาษาถิ่นอีสาน - Copy.xlsx\"\n",
    "south_path = r\"datasets\\พจนานุกรมภาษาถิ่นใต้ - Copy.xlsx\"\n",
    "orst_path = r\"datasets\\ราชบัณฑิตฯ - Copy\"\n",
    "\n",
    "def load_sheets(file_path, exclude_sheets):\n",
    "    all_sheets = pd.ExcelFile(file_path).sheet_names\n",
    "    importing_sheets = [sheet for sheet in all_sheets if sheet not in exclude_sheets]\n",
    "    return pd.read_excel(file_path, sheet_name=importing_sheets, header=None)\n",
    "\n",
    "north_df = pd.read_excel(north_path, sheet_name=None, header=None)\n",
    "isan_df = pd.read_excel(isan_path, sheet_name=None, header=None)\n",
    "south_df = pd.read_excel(south_path, sheet_name=None, header=None)\n",
    "\n",
    "def load_excel(directory):\n",
    "    excel_files = {}\n",
    "    for filename in os.listdir(directory):\n",
    "        name = os.path.splitext(filename)[0]\n",
    "        excel_files[name] = pd.read_excel(os.path.join(directory, filename), header=None)\n",
    "    return excel_files\n",
    "\n",
    "orst_df = load_excel(orst_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38649c71",
   "metadata": {},
   "source": [
    "## Inspect the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db0730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to copy\n",
    "\n",
    "north = north_df.copy()\n",
    "isan = isan_df.copy()\n",
    "south = south_df.copy()\n",
    "orst = orst_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7b0ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the data\n",
    "\n",
    "def inspect(num=10, *dfs):\n",
    "  for df in dfs:\n",
    "    for key in df.keys():\n",
    "      print(f\"{key}\\n{df[key].head(num)}\\n\")\n",
    "\n",
    "inspect(5, north, south, isan, orst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee626f67",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8e3e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning\n",
    "def shift_left(row):\n",
    "    values = [val for val in row if pd.notna(val)]\n",
    "    return pd.Series(values + [None] * (len(row) - len(values)))\n",
    "\n",
    "def cleaning(*dfs):\n",
    "    for df in dfs:\n",
    "        removed = [\n",
    "            'ช่อง 1', 'ลูกคำ/ ความหมาย', 'แม่คำ', 'ความหมายลูกคำ คำสื่อ',\n",
    "            'headword', '2', '3']\n",
    "\n",
    "        for key in df.keys():\n",
    "            if df == north or df == south or df == isan:\n",
    "                df[key] = df[key][~df[key].apply(lambda row: any(string in str(val) for string in removed for val in row), axis=1)]\n",
    "                df[key] = df[key].dropna(how='all')\n",
    "                df[key] = df[key].drop(df[key].columns[2:], axis=1)\n",
    "                df[key] = df[key].fillna(\"\")\n",
    "                df[key].columns = ['word', 'meaning']\n",
    "\n",
    "            elif df == orst:\n",
    "                df[key] = df[key].iloc[:, :-1]\n",
    "                df[key].iloc[:, 0] = df[key].apply(lambda row: row.iloc[1] if pd.isnull(row.iloc[0]) else row.iloc[0], axis=1)\n",
    "                df[key] = df[key].drop(columns=[df[key].columns[1]])\n",
    "                df[key] = df[key].reset_index(drop=True)\n",
    "                df[key].columns = ['word', 'meaning']\n",
    "                df[key] = df[key].iloc[1:]\n",
    "\n",
    "cleaning(north, isan, south, orst)\n",
    "\n",
    "inspect(10, north, isan, south, orst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8103cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb56140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(df):\n",
    "    for key in df.keys():\n",
    "        # print(df[key].columns)\n",
    "        print(df[key].shape)\n",
    "\n",
    "func(orst)\n",
    "\n",
    "# orst[\"หมวด_ฬ(1)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3429141c",
   "metadata": {},
   "source": [
    "## Split POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6324399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rearrange(df):\n",
    "  for key in df.keys():\n",
    "    pattern = r\"^(น\\.|\\*น\\.|นิ\\.|ก\\.|\\*ก\\.|ว\\.|\\*ว\\.|สัน\\.|ส\\.|บุรพ\\.|\\*ส\\.|สำ\\.|สำนวน\\.|สำนวน\\.\\*|คำลงท้าย\\.|คำยกย่อง\\.|อาลปนะ\\.|ลัก\\.|สรรพ\\.|อ\\.|\\*อ\\.|อุ\\.|ความเปรียบ\\.|คำถาม\\.|บุพ\\.|บ\\.)(.*)$\"\n",
    "    \n",
    "    df[key][\"คำ\"] = df[key]['word']\n",
    "    df[key][\"POS\"] = \"\"\n",
    "    df[key][\"ความหมาย\"] = \"\"\n",
    "\n",
    "    if df[key]['meaning'].str.startswith((\n",
    "      \"น.\", \"*น.\", \"นิ.\", \"ก.\", \"*ก.\", \"ว.\", \"*ว.\", \"สัน.\", \"สำ.\", \"ส.\", \"*ส.\", \"ความเปรียบ.\", \"คำถาม.\", \"คำยกย่อง.\",\n",
    "      \"บุพ.\", \"บ.\", \"บุรพ.\", \"สำนวน.\", \"สำนวน.*\", \"ลัก.\", \"สรรพ.\", \"อ.\", \"*อ.\", \"อุ.\", \"อุทาน.\", \"คำลงท้าย.\")).any():\n",
    "    \n",
    "      df[key][[\"POS\", \"ความหมาย\"]] = df[key]['meaning'].str.extract(pattern, expand=True)\n",
    "      df[key][\"ความหมาย\"] = df[key].apply(lambda row: row[2] if row[\"POS\"] == \"\" else row[\"ความหมาย\"], axis=1)\n",
    "\n",
    "    # fill no POS\n",
    "    pos_mask = df[key]['meaning'].str.match(pattern, na=False)\n",
    "    df[key][\"POS\"] = df[key][\"POS\"].fillna(\"\")\n",
    "    df[key].loc[~pos_mask, \"ความหมาย\"] = df[key].loc[~pos_mask, 'meaning']\n",
    "\n",
    "    # remove first two columns\n",
    "    df[key] = df[key].iloc[:, 2:]\n",
    "\n",
    "rearrange(orst)\n",
    "rearrange(north)\n",
    "rearrange(south)\n",
    "rearrange(isan)\n",
    "\n",
    "def clean_whitespace(df):\n",
    "  for key in df.keys():\n",
    "    for column in df[key].columns:\n",
    "      if df[key][column].dtype == 'object':\n",
    "        df[key][column] = df[key][column].apply(\n",
    "          lambda text: ' '.join(text.split()) if isinstance(text, str) else text\n",
    "        )\n",
    "  return df\n",
    "\n",
    "orst = clean_whitespace(orst)\n",
    "north = clean_whitespace(north)\n",
    "south = clean_whitespace(south)\n",
    "isan = clean_whitespace(isan)\n",
    "\n",
    "inspect(10, north, isan, south, orst)\n",
    "\n",
    "# orst['หมวด_ก(3881)'].head(n=40)\n",
    "# north['ก'].head(n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384930b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pythainlp.util import collate\n",
    "def fill_blank_words(iter=2, *dfs):\n",
    "    for df in dfs:\n",
    "        for _ in range(iter):\n",
    "            for key in df.keys():\n",
    "                df[key] = df[key].dropna(how='all')\n",
    "                df[key] = df[key].infer_objects(copy=False)\n",
    "                df[key] = df[key].replace(r'^\\s*$', np.nan, regex=True) \n",
    "                df[key] = df[key].ffill()\n",
    "                df[key].drop_duplicates(inplace=True)\n",
    "                df[key] = df[key].sort_values(by=\"คำ\")\n",
    "                df[key][\"คำ\"] = collate(df[key][\"คำ\"])\n",
    "                df[key] = df[key].reset_index(drop=True)\n",
    "        return df\n",
    "\n",
    "fill_blank_words(2, north, isan, south, orst)\n",
    "\n",
    "inspect(10, north, isan, south, orst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c566b0bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7207b13c",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2dbaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output\n",
    "\n",
    "def df_to_csv(dfs, region, path):\n",
    "    for sheet, df in dfs.items():\n",
    "        file = f\"{path}/{region}_{sheet}.csv\"\n",
    "        df.to_csv(file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "regions = {\n",
    "    'north': north,\n",
    "    'isan': isan,\n",
    "    'south': south,\n",
    "    'cen': orst\n",
    "    }\n",
    "\n",
    "for region, dfs in regions.items():\n",
    "    df_to_csv(dfs, region, r\"output\\csv_test1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a9727c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90951ffb",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ff3643",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "th_dialect_dict",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
